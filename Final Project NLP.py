# -*- coding: utf-8 -*-
"""202010370311336_Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-gkgwjVD4lVPJZ76OGaxIju_1dsNXCG2

# **Kelompok NLP**

1.   Vita Amalia Herlinda (202010370311336)
2.   Arolina Rinardi      (202010370311343)
3.   Nurlaila Rhamadani   (202010370311046)

# **Mendeteksi SMS spam atau bukan**
Kumpulan Data sms spam  adalah sekumpulan pesan SMS publik dalam bahasa Inggris yang telah dikumpulkan untuk penelitian spam ponsel. Kumpulan data berisi 5.574 pesan yang telah ditandai sebagai ham atau spam.

# **Tujuan**


*  Untuk memdeteksi sms apakah spam atau bukan
*  Bisa mengurangi angka penipuan melalui sms melalui ponsel.

# **Teknik analisis teks**


*   BoW (Bag of Word)
*   N-Gram
*   TFIDF
*   Word2Vec
     *    Glove Menggunakan Library Gensim
     *    FastText Menggunakan Library Gensim
     *    Bert Menggunakan Library Hugging Face

# **Dataset**
*   source :  https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset
*   5572 baris
*   5 fitur/atribut.

# **A.Target Data/Dependent Variable**
**Label** : Apakah SMS teks  termasuk dalam kategori "spam" atau "ham".

# **B.Predictor/Independent Variable**

1.   v2 : berisi isi teks dari setiap pesan SMS
2.   Unnamed:2 : NaN
3.   Unnamed:3 : NaN
4.   Unnamed:4 : NaN
"""

# Download dataset
!wget --no-check-certificate \
  https://drive.google.com/file/d/1FFUpt0oQS1TeUQNCTl3UxliIk4zwMNz-/view?usp=sharing \
  -O //tmp/Spam Chat.zip

# Ekstrak dataset

import os
import zipfile
from google.colab import drive

drive.mount('/content/drive/')

zip_ref = zipfile.ZipFile("/content/drive/My Drive/Colab Notebooks/Spam Chat.zip", 'r')
zip_ref.extractall("/tmp")
zip_ref.close()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
import re
import sklearn
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

import pandas as pd
from sklearn.metrics import classification_report

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Spam Chat.zip', encoding='latin-1')
df.head()

"""# **Exploratory Data Analysis (EDA)**"""

df.shape

df.dtypes

df.isnull().sum()

df.columns

df['v1'].value_counts()

plt.figure(figsize=(8,5))
sns.countplot(x='v1', data=df)
plt.xlabel('SPAM Classification')
plt.ylabel('Count')
plt.show()

"""# **Preprocessing**

Data Cleaning
"""

df = df.iloc[:,:2]

df.columns = ['label','message']
df.head()

"""Membersihkan pesan
*  Corpus digunakan untuk menyimpan pesan yang telah di melewati proses pembersihan.
"""

corpus = []
ps = PorterStemmer()

for i in range(0,df.shape[0]):
    message = re.sub(pattern='[^a-zA-Z]', repl=' ', string=df.message[i]) #Cleaning special character from the message
    message = message.lower() #Converting the entire message into lower case
    words = message.split() # Tokenizing the review by words
    words = [word for word in words if word not in set(stopwords.words('english'))] #Removing the stop words
    words = [ps.stem(word) for word in words] #Stemming the words
    message = ' '.join(words) #Joining the stemmed words
    corpus.append(message) #Building a corpus of messages

"""Data transformation


*   One Hot Encoding (OHE) : `label`


"""

y = pd.get_dummies(df['label'])
y = y.iloc[:, 1].values

y

# menggabungkan hasil one-hot encoding dengan DataFrame asli
df_encoded = pd.concat([df, pd.DataFrame(y, columns=['label'])], axis=1)

# menampilkan 5 baris pertama dari DataFrame hasil encoding
print(df_encoded.head())

"""# **BOW**"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=2500)
X = cv.fit_transform(corpus).toarray()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(0.0,1.1,0.1):
    temp_classifier = MultinomialNB(alpha=i)
    temp_classifier.fit(X_train, y_train)
    temp_y_pred = temp_classifier.predict(X_test)
    score = accuracy_score(y_test, temp_y_pred)
    print("Accuracy score for alpha={} is: {}%".format(round(i,1), round(score*100,2)))
    if score>best_accuracy:
        best_accuracy = score
        alpha_val = i
print('--------------------------------------------')
print('The best accuracy is {}% with alpha value as {}'.format(round(best_accuracy*100, 2), round(alpha_val,1)))

"""**Model klasifikasi**
*   Multinomial Naive Bayes
"""

classifier = MultinomialNB(alpha=0.1)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# y_test and y_pred are the true and predicted labels, respectively
acc_s = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy Score {} %".format(round(acc_s,2)))
print("Precision Score: {:.2f}".format(precision))
print("Recall Score: {:.2f}".format(recall))
print("F1 Score: {:.2f}".format(f1))
print(classification_report(y_test, y_pred))

""" **Deteksi Spam aatau bukan**"""

def predict_spam(sample_message):
    sample_message = re.sub(pattern='[^a-zA-Z]',repl=' ', string = sample_message)
    sample_message = sample_message.lower()
    sample_message_words = sample_message.split()
    sample_message_words = [word for word in sample_message_words if not word in set(stopwords.words('english'))]
    ps = PorterStemmer()
    final_message = [ps.stem(word) for word in sample_message_words]
    final_message = ' '.join(final_message)
    temp = cv.transform([final_message]).toarray()
    return classifier.predict(temp)

result = ['Ini pesan SPAM!','Ini pesan HAM!.']

msg = "07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow."
if predict_spam(msg):
    print(result[0])
else:
    print(result[1])

msg = "Even my brother is not like to speak with me. They treat me like aids patent."

if predict_spam(msg):
    print(result[0])
else:
    print(result[1])

"""# **N-Gram**"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Split the dataset into training and test sets
train_data, test_data, train_labels, test_labels = train_test_split(df["message"], df["label"], test_size=0.2, random_state=42)

# Extract N-Gram features of the SMS messages
vectorizer = CountVectorizer(ngram_range=(1, 2))
X_train = vectorizer.fit_transform(train_data)
X_test = vectorizer.transform(test_data)

""" **Model klasifikasi**
* Bernoulli Naive Bayes
"""

# Train a Bernoulli Naive Bayes model on the N-Gram features
clf = BernoulliNB()
clf.fit(X_train, train_labels)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(X_test)
report = classification_report(test_labels, y_pred)
precision = precision_score(test_labels, y_pred, pos_label="spam")
recall = recall_score(test_labels, y_pred, pos_label="spam")
f1score = f1_score(test_labels, y_pred, pos_label="spam")
print(report)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)

"""**Deketsi sms spam atau ham**"""

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    message = [message]
    message = vectorizer.transform(message)
    prediction = clf.predict(message)
    if prediction[0] == "spam":
        return "Ini adalah sms Spam!!"
    else:
        return "Ini adalah Ham"

# Example usage of the predict_spam function
message = "Is that seriously how you spell his name?"
result = predict_spam(message)
print(result)

"""# **TFIDF**"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score

# Split the dataset into training and test sets
train_data, test_data, train_labels, test_labels = train_test_split(df["message"], df["label"], test_size=0.2, random_state=42)

# Extract TF-IDF features of the SMS messages
vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(train_data)
X_test = vectorizer.transform(test_data)

"""**Model klasifikasi**
*   Bernoulli Naive Bayes
"""

# Train a Bernoulli Naive Bayes model on the TF-IDF features
clf = BernoulliNB()
clf.fit(X_train, train_labels)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(X_test)
report = classification_report(test_labels, y_pred)
precision = precision_score(test_labels, y_pred, pos_label="spam")
recall = recall_score(test_labels, y_pred, pos_label="spam")
f1score = f1_score(test_labels, y_pred, pos_label="spam")
print(report)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    message = [message]
    message = vectorizer.transform(message)
    prediction = clf.predict(message)
    if prediction[0] == 1:
        return "Ini adalah sms Spam!!"
    else:
        return "Ini adalah sms Ham"

# Example usage of the predict_spam function
message = "Thanks for your subscription to Ringtone UK your mobile will be charged å£5/month Please confirm by replying YES or NO. If you reply NO you will not be charged"
result = predict_spam(message)
print(result)

"""# **Word2Vec**"""

import pandas as pd
import gensim
from gensim.models import Word2Vec
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score

# Split the dataset into training and test sets
train_data, test_data, train_labels, test_labels = train_test_split(df["message"], df["label"], test_size=0.2, random_state=42)

# Tokenize the SMS messages
train_tokens = [gensim.utils.simple_preprocess(text) for text in train_data]
test_tokens = [gensim.utils.simple_preprocess(text) for text in test_data]

# Train the Word2Vec model on the training set
model = Word2Vec(train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=1, epochs=10)

# Extract Word2Vec embeddings of the SMS messages
X_train = []
for tokens in train_tokens:
    embeddings = []
    for token in tokens:
        if token in model.wv:
            embeddings.append(model.wv[token])
    if len(embeddings) > 0:
        embeddings = sum(embeddings) / len(embeddings)
    else:
        embeddings = [0] * 100
    X_train.append(embeddings)
X_test = []
for tokens in test_tokens:
    embeddings = []
    for token in tokens:
        if token in model.wv:
            embeddings.append(model.wv[token])
    if len(embeddings) > 0:
        embeddings = sum(embeddings) / len(embeddings)
    else:
        embeddings = [0] * 100
    X_test.append(embeddings)

"""Model Klasifikasi
*  Logistic Regression
"""

# Train a logistic regression model on the Word2Vec embeddings
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()
clf.fit(X_train, train_labels)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(X_test)
report = classification_report(test_labels, y_pred)
precision = precision_score(test_labels, y_pred, pos_label="spam")
recall = recall_score(test_labels, y_pred, pos_label="spam")
f1score = f1_score(test_labels, y_pred, pos_label="spam")
print(report)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    tokens = gensim.utils.simple_preprocess(message)
    embeddings = []
    for token in tokens:
        if token in model.wv:
            embeddings.append(model.wv[token])
    if len(embeddings) > 0:
        embeddings = sum(embeddings) / len(embeddings)
    else:
        embeddings = [0] * 100
    prediction = clf.predict([embeddings])
    if prediction[0] == "spam":
        return "Ini adalah sms Spam!!"
    else:
        return "Ini adalah sms Ham"

# Example usage of the predict_spam function
message = "So wat's da decision?"
result = predict_spam(message)
print(result)

"""# **Glove**"""

"My Drive/Place/Of/Your/Choice/glove.6B.300d.txt"

!pip install gensim

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, precision_score, recall_score, f1_score
from gensim.scripts.glove2word2vec import glove2word2vec
from gensim.models import KeyedVectors

# Split the dataset into training and test sets
train_data, test_data, train_labels, test_labels = train_test_split(df["message"], df["label"], test_size=0.2, random_state=42)

# Convert GloVe format to Word2Vec format
glove_input_file = "glove.6B.100d.txt"
word2vec_output_file = "glove.6B.100d.word2vec.txt"
glove2word2vec(glove_input_file, word2vec_output_file)

# Load the GloVe model in Word2Vec format using gensim
model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)

# Extract GloVe embeddings of the SMS messages
X_train = []
for text in train_data:
    embeddings = []
    for word in text.split():
        if word in model:
            embeddings.append(model[word])
    if len(embeddings) > 0:
        embeddings = np.mean(embeddings, axis=0)
    else:
        embeddings = np.zeros(100)
    X_train.append(embeddings)
X_test = []
for text in test_data:
    embeddings = []
    for word in text.split():
        if word in model:
            embeddings.append(model[word])
    if len(embeddings) > 0:
        embeddings = np.mean(embeddings, axis=0)
    else:
        embeddings = np.zeros(100)
    X_test.append(embeddings)

"""**Model** klasifikasi
* Logistic Regression
"""

# Train a logistic regression model on the GloVe embeddings
clf = LogisticRegression()
clf.fit(X_train, train_labels)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(X_test)
report = classification_report(test_labels, y_pred)
precision = precision_score(test_labels, y_pred, pos_label="spam")
recall = recall_score(test_labels, y_pred, pos_label="spam")
f1score = f1_score(test_labels, y_pred, pos_label="spam")
print(report)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    embeddings = []
    for word in message.split():
        if word in model:
            embeddings.append(model[word])
    if len(embeddings) > 0:
        embeddings = np.mean(embeddings, axis=0)
    else:
        embeddings = np.zeros(100)
    prediction = clf.predict([embeddings])
    if prediction[0] == 1:
        return "Ini adalah sms Spam!!"
    else:
        return "Ini adalah sms Ham"

# Example usage of the predict_spam function
message = "Mobile Club: Choose any of the top quality items for your mobile. 7cfca1a"
result = predict_spam(message)
print(result)

"""# **Fasstext (Gensim)**"""

import pandas as pd
import gensim
from gensim.models.fasttext import FastText
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Split the dataset into training and test sets
train_data, test_data, train_labels, test_labels = train_test_split(df["message"], df["label"], test_size=0.2, random_state=42)

# Tokenize the SMS messages
train_tokens = [gensim.utils.simple_preprocess(text) for message in train_data]
test_tokens = [gensim.utils.simple_preprocess(text) for message in test_data]

# Train the FastText model on the training set
model = FastText(train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=1, epochs=10)

# Extract FastText embeddings of the SMS messages
X_train = []
for tokens in train_tokens:
    embeddings = model.wv[tokens].mean(axis=0)
    X_train.append(embeddings)
X_test = []
for tokens in test_tokens:
    embeddings = model.wv[tokens].mean(axis=0)
    X_test.append(embeddings)

"""Model klasifikasi
* Logistic Regression
"""

# Train a logistic regression model on the FastText embeddings
clf = LogisticRegression()
clf.fit(X_train, train_labels)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(X_test)
accuracy = accuracy_score(test_labels, y_pred)
precision = precision_score(test_labels, y_pred, pos_label="spam")
recall = recall_score(test_labels, y_pred, pos_label="spam")
f1score = f1_score(test_labels, y_pred, pos_label="spam")
report = classification_report(test_labels, y_pred)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)
print("Classification Report:\n", report)

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    tokens = gensim.utils.simple_preprocess(message)
    embeddings = model.wv[tokens].mean(axis=0)
    prediction = clf.predict([embeddings])
    if prediction[0] == "spam":
        return "Ini adalah sms spam."
    else:
        return "Ini bukan sms spam"

# Example usage of the predict_spam function
message = "Oh k...i'm watching here"
result = predict_spam(message)
print(result)

"""# **BERT (Hugging Face)**"""

!pip install transformers

import pandas as pd
import torch
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertModel
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix
from sklearn.metrics import classification_report

# Load pre-trained BERT model and tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertModel.from_pretrained('distilbert-base-uncased')

# Convert SMS messages into BERT inputs
X = []
for sentence in df["message"]:
    inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, return_tensors='pt')
    X.append(inputs)

# Convert labels into integers
y = df["label"].apply(lambda x: 1 if x == "spam" else 0)

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Extract BERT embeddings of the SMS messages
embeddings_train = []
for inputs in X_train:
    outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()
    embeddings_train.append(embeddings)
embeddings_test = []
for inputs in X_test:
    outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()
    embeddings_test.append(embeddings)

"""Model klasifikasi
* Logitisc Regression
"""

# Train a logistic regression model on the BERT embeddings
clf = LogisticRegression()
clf.fit(embeddings_train, y_train)

# Evaluate the performance of the model on the test set
y_pred = clf.predict(embeddings_test)
accuracy = clf.score(embeddings_test, y_test)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1score = f1_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1score)
print("Classification Report:\n", report)

# Function to predict whether an SMS message is spam or not
def predict_spam(message):
    inputs = tokenizer.encode_plus(message, add_special_tokens=True, return_tensors='pt')
    outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()
    prediction = clf.predict([embeddings])
    if prediction[0] == 1:
        return "Ini pesan Spam!!!"
    else:
        return "Ini pesan Ham"

# Example usage of the predict_spam function
message = "XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL"
result = predict_spam(message)
print(result)